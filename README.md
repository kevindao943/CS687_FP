# CS687_Final_Project

Select two RL algorithms that were not covered in class and evaluate each of them on at least
two existing MDPs/domains. Since the point of this project is to implement these methods from
scratch, you should not use existing code for the RL algorithms—though you may use existing
code for the environments that you test. Examples of algorithms that we have not covered in class
that could be a good fit are the REINFORCE with Baseline algorithm (Section 13.4 of the RL
book), the One-Step Actor-Critic algorithm for episodic tasks (Section 13.5 of the RL book), a
model-based RL algorithm such as Prioritized Sweeping (Section 8.4 of the RL book), the Monte
Carlo Tree Search (MCTS) algorithm (Section 8.11 of the RL book), the Episodic Semi-Gradient
n-step SARSA algorithm (Section 10.2 of the RL book), the True Online SARSA(λ) algorithm
(Section 12.7 of the RL book), and the PI2-CMA-ES algorithm from the paper Path Integral
Policy Improvement with Covariance Matrix Adaptation.

In the write-up for a project of this sort you should include...

(i) a brief description of the methods and what they do; 

(ii) pseudocode for the methods; 

(iii) adiscussion of how you tuned their hyper-parameters; 

(iv) the corresponding experimental results. 

When analyzing the performance of each algorithm, you should present learning curves
such as the ones in the homework assignments.


Meeting on Sunday:

Sean: Finish up write up for hyperameters tuning and algorithm. Include learning curves

Kevin: Fine-tuning (ES), and add write-up.

For Sunday, proofread write-up.
